# 4장 커넥션 관리

이 장에서는 아래와 같은 내용을 배운다.

- HTTP는 어떻게 TCP 커넥션을 사용하는가
- TCP 커넥션의 지연, 병목, 막힘
- 병렬 커넥션, keep-alive 커넥션, 커넥션 파이프라인을 활용한 HTTP의 최적화
- 커넥션 관리를 위해 따라야 할 규칙들

## 4.1 TCP 커넥션

전 세계의 HTTP 통신은 **TCP/IP라는 계층화된 네트워크 프로토콜 묶음** 위에서 이루어진다.

클라이언트는 TCP/IP를 통해 서버와 **연결(TCP 커넥션)**을 맺고, 연결이 만들어지면 클라이언트와 서버 사이의 메시지는 **손실·손상·순서 뒤바뀜 없이** 안전하게 전달된다.

<img width="504" height="413" alt="image" src="https://github.com/user-attachments/assets/68235838-fff2-4e55-85e9-764143277e06" />

- HTTP 요청/응답 전에 TCP 커넥션을 생성한다.

### 4.1.1 신뢰할 수 있는 데이터 전송 통로인 TCP

- TCP 커넥션은 인터넷에서 두 지점을 안정적으로 연결해 신뢰성 있는 전송을 제공한다
- 신속하고 정확한 데이터 전송을 원한다면 TCP의 기초 동작을 이해해야 한다
- TCP는 HTTP에게 신뢰할 만한 통신 방식을 제공해 한쪽에서 보낸 바이트가 반대쪽에 순서에 맞게 정확히 전달되게 한다

<img width="517" height="166" alt="image" src="https://github.com/user-attachments/assets/9e306d64-7867-467e-adec-4ae50e5f1631" />

### 4.1.2 TCP 스트림은 세그먼트로 나뉘어 IP 패킷을 통해 전송된다.

TCP는 IP 패킷이라고 불리는 작은 조각을 통해 데이터를 전송한다.

HTTP는 전송, 네트워크, 데이터 링크 계층으로 감싸진 최상위 계층이며 TLS가 포함된 암호화 기능이 추가된 HTTPS도 존재한다.

<img width="504" height="215" alt="image" src="https://github.com/user-attachments/assets/8c69942a-e383-4b3c-a318-f056750b1471" />

> 💡 **HTTP vs HTTPS 커넥션 차이**
>
> - HTTP: TCP 핸드쉐이크 → HTTP 요청
> - HTTPS: TCP 핸드쉐이크 → TLS 핸드쉐이크 → HTTP 요청

IP패킷은 아래의 구성요소로 이루어 진다.

- IP 패킷 헤더(보통 20바이트)
    - 발신지와 목적지 IP 주소, 크기, 기타 플래그
- TCP 세그먼트 헤더(보통 20바이트)
    - TCP 포트 번호, TCP 제어 플래그, 그리고 데이터의 순서와 무결성을 검사하 기 위해 사용되는 숫자 값
- TCP 데이터 조각(O 혹은 그 이상의 바이트)

세그먼트 순서 번호를 통해 순서를 보장한다.

<img width="514" height="474" alt="image" src="https://github.com/user-attachments/assets/53823c0b-44ca-4b22-ace7-e7669f6ccaf3" />

> 💡 전송 단위:
>
> - TCP는 세그먼트 단위로 전송
> - IP는 패킷 단위로 전송
>
> 각 계층에서 캡슐화/역캡슐화가 일어나며, IP는 전달만 담당하고 TCP가 신뢰성을 보장한다.
>

> 💡 MTU와 MSS:
>
> - **MTU**(Maximum Transmission Unit): 네트워크에서 보낼 수 있는 최대 패킷 크기 (이더넷 기준 1500바이트)
> - **MSS**(Maximum Segment Size): TCP 페이로드 최대 크기 (MTU - IP헤더 - TCP헤더 ≈ 1460바이트)
>
> HTTP 요청이 MSS를 넘으면 내부적으로 여러 TCP 세그먼트로 분할되어 전송된다.
>

### 4.1.3 TCP 커넥션 유지하기

컴퓨터는 항상 TCP 커넥션을 여러 개 가지고 있다. TCP는 포트 번호를 통해서 이런 여러 개의 커넥션을 유지한다.

TCP커넥션은 아래 4개의 요소로 이루어진다.

```jsx
<발신지 IP 주소, 발신지 포트, 수신지 IP 주소, 수신지 포트>
```

- 일부 구성요소가 같을순 있지만 4개의 요소는 유니크하며 전체가 같을 수 없다.

### 4.1.4 TCP 소켓 프로그래밍

간단히 말하면 소켓은 TCP/IP를 사용하기 위한 추상화된 인터페이스이다.

- 내부 TCP/IP 구현을 숨겨 인터페이스만을 이용하여 TCP통신을 가능하게한다.

<img width="486" height="303" alt="image" src="https://github.com/user-attachments/assets/fa6c60a6-46d8-4103-beba-09f572d288a1" />

> 💡 **HTTP 통신 vs 소켓 통신 개념 정리:**
>
> - **소켓**: 네트워크 통신을 위한 OS 인터페이스 (프로토콜이 아님)
> - Unix에서 소켓은 파일 디스크립터로 취급됨 → read/write로 데이터 송수신
> - HTTP도 내부적으로 소켓을 사용함
> - "소켓 통신"이라 하면 보통 HTTP 없이 TCP/UDP를 직접 다루는 방식을 의미
> - 정확한 비교: "HTTP 기반 통신" vs "TCP/UDP 직접 통신 (raw socket)"

<img width="552" height="341" alt="image" src="https://github.com/user-attachments/assets/e9272c89-0e42-4ce5-8e1e-de6a69fedf89" />

- 소켓 API를 사용하여 TCP 커넥션을 완료 한 후, HTTP 요청/응답을 처리한다.

## 4.2 TCP의 성능에 대한 고려

HTTP는 TCP 바로 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 그 아래 계층인 TCP 성능에 영향을 받는다.

이 절에서는 TCP 커넥션 성능에 대한 고려사항을 알아본다.

### 4.2.1 HTTP 트랜잭션 지연

HTTP 지연은 대부분 트랜잭션 처리보다 TCP 네트워크 지연 때문에 발생한다.

- DNS resolve
- TCP 핸드쉐이크
- 요청/응답 네트워크 지연

일반적으로 이 요소들이 서버가 트랜잭션을 처리하는 것보다 지연이 크게 발생한다.

<img width="488" height="200" alt="image" src="https://github.com/user-attachments/assets/5fe0e964-476f-4781-80ee-f0d5d5538c31" />

### 4.2.2 성능 관련 중요 요소

HTTP프로그래머에게 영향을 주는 가장 일반적인 성능 지연 요소들에 대해 알아본다.

- TCP 커넥션의 핸드셰이크 설정
- 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
- 데이터를 한데 모아 한 번에 전송하기 위한 네이글(nagle) 알고리즘
- TCP의 편승(piggyback) 확인응답(acknowledgment)을 위한 확인응답 지연 알고리즘
- TIME_WAIT 지연과 포트 고갈

### 4.2.3 TCP 커넥션 핸드셰이크 지연

어떤 데이터를 전송하든 새로운 TCP 커넥션을 열 때면, TCP 소프트웨어는 커넥션을 맺기 위한 조건을 맞추기 위해 연속으로 IP 패킷을 교환한다.

- 작은 데이터 전송을 위한 커넥션은 성능을 크게 감소시킨다.

<img width="530" height="219" alt="image" src="https://github.com/user-attachments/assets/ffedff53-3e06-42b0-8585-9616faeb60db" />

- SYN
- SYN + ACK
- ACK + (오늘날에는 DATA전송 가능)
- HTTP

IP패킷에 크기는 대략 1500 바이트인데, 작은 양의 데이터 전송을 위해 적은 양의 패킷을 주고받는것은 낭비다.

다음장에서 커넥션을 어떻게 재활용 하는지 알아본다.

### 4.2.4 확인 응답 지연

인터넷 자체가 패킷 전송을 완벽히 보장하지는 않기 때문에 , TCP는 성공적인 데이터 전송을 보장하기 위해서 자체적인 확인 체계를 가진다.

TCP는 세그먼트 순서번호를 통해 순서보장하고 데이터 무결성 체크섬을 통해 오류를 발견하면 재전송 한다.

각 세그먼트의 수신 자는 세그먼트를 온전히 받으면 작은 확인웅답 패킷을 송신자에게 반환한다.

### Piggyback(편승)과 Delayed ACK(확인응답 지연)

- Piggyback
    - ACK는 작기 때문에 TCP는 효율을 위해 **같은 방향으로 나가는 데이터 패킷에 ACK를 붙여서** 보내기도 한다.
- piggyback을 더 잘 하려고 많은 TCP 스택이 **Delayed ACK**를 쓴다.
    - ACK를 바로 보내지 않고 **잠깐(보통 0.1~0.2초)** 모아둠
    - 그 사이에 반대편으로 보낼 데이터가 생기면 **그 데이터에 ACK를 편승**
    - 일정 시간 내에 보낼 데이터가 없으면 ACK를 **단독 패킷으로 전송**
- HTTP는 기본적으로 **요청 → 응답** 패턴이라,어떤 순간에는 "그 방향으로 나갈 데이터"가 거의 없다.
    - 그래서 ACK를 편승시키려다 못하고 **Delayed ACK 타이머만큼 지연**이 자주 생길 수 있다.
- OS마다 설정이 다르지만, 이 지연의 원인을 **조정하거나 비활성화** 할 수 있다.
    - TCP 내부 알고리즘은 잘못된 **애플리케이션이 인터넷을 망치지 못하게** 보호하려고 설계된 되어있다.
    - TCP 튜닝 시에는 주의가 필요

### 4.2.5 TCP 느린 시작(slow start)

- TCP는 새 연결에서 혼잡을 피하려고 처음엔 전송량을 제한한다(slow start).
- 성공적으로 ACK를 받으면 더 많이 보낼 수 있게 점점 늘린다.
    - 혼잡윈도를 연다고 표현
- 그래서 새 커넥션은 초반에 느리고, 오래 유지된 커넥션은 더 빠르다.
- HTTP는 새 커넥션을 계속 만들면 손해를 본다.
- 그래서 커넥션 재사용(지속 커넥션)이 성능에 중요하다.

### 4.2.6 네이글(Nagle) 알고리즘과 TCP_NODELAY

- TCP는 애플리케이션이 1바이트 같은 아주 작은 데이터도 보낼 수 있게 **스트림 인터페이스**를 제공한다.

  그런데 TCP 세그먼트는 전송할 때마다 **헤더(대략 40바이트 수준)** 같은 오버헤드가 붙어서, 작은 데이터를 자주 보내면 **패킷 수가 폭증**하고 네트워크 효율이 크게 떨어질 수 있다.

- 이 비효율을 줄이려고 나온 게 **네이글(Nagle) 알고리즘**이다.
    - **작은 데이터를 바로바로 보내지 말고, 버퍼에 모아서 큰 덩어리로 합친 뒤 전송**하자는 것.
    - 동작 원리
        - 세그먼트가 **충분히 커질 때까지**는 전송을 미루고 버퍼에 쌓는다.
        - 단, **이전에 보낸 데이터가 모두 ACK(확인응답)를 받은 상태**면 작은 패킷 전송도 허용한다.
        - 반대로 아직 ACK를 못 받은 데이터가 있으면(= 전송 중인 데이터가 있으면) 새로 생긴 작은 데이터는 **버퍼에 대기**한다.
        - ACK가 오거나, 데이터가 충분히 모이면 전송한다.
- 문제는 **HTTP 메시지가 작고(요청/응답 위주)** "더 모을 데이터가 같은 방향으로 안 생기는 순간"이 많다는 점이다.

  그래서 네이글 알고리즘은 데이터가 쌓일 때까지 **불필요한 지연**이 생길 수 있다.

- 특히 **Delayed ACK(확인응답 지연)** 과 같이 켜져 있으면 최악의 조합이 된다.
    - 네이글: ACK 올 때까지 전송을 멈추는 쪽(작은 데이터는 모으려고)
    - Delayed ACK: ACK를 100~200ms 일부러 늦게 보내는 쪽

      → 서로가 서로를 기다리면서 **100~200ms급 지연이 빈번히 발생**할 수 있다.

- 그래서 HTTP 성능을 위해 애플리케이션/라이브러리에서 **TCP_NODELAY**를 켜서 **네이글을 비활성화**하기도 한다.
    - 작은 패킷이 너무 많이 생길 수 있으니, **가능하면 큰 덩어리로 보내는 습관**이 필요하다.

### 4.2.7 TIME_WAIT의 누적과 포트 고갈

- **TIME_WAIT 포트 고갈은 실서비스에선 보통 잘 안 터지지만**, 성능 측정(부하 테스트)에서는 자주 문제가 된다. 그래서 벤치 결과가 갑자기 나빠지면 "서버 성능 문제"로 오해하기 쉬워서 조심해야 한다.
- TCP 커넥션을 종료하면, 종료한 쪽(보통 클라이언트)이 `<IP/포트>` 조합을 **메모리의 제어 블록(control block)** 에 잠깐 기록해 둔다.
    - **이전 커넥션의 늦게 도착한 패킷이 새 커넥션에 섞이는 사고를 방지**하려고.
- 이 대기 시간이 보통 **2MSL**(Maximum Segment Lifetime의 2배)이고, 책에서는 **대략 2분(120초)** 정도로 설명한다.
    - 즉, 같은 4-튜플(아래)을 **바로 재사용 못하게 막는 안전장치**다.
- TCP 커넥션은 아래 4개 값(4-tuple)으로 유일하게 식별된다.

  `<발신지 IP, 발신지 포트, 목적지 IP, 목적지 포트>`

  부하 테스트에서 흔히 **서버 IP + 서버 포트(80)는 고정**, 클라이언트도 몇 대 안 쓰면 **클라이언트 IP도 사실상 고정**이 된다.

  그럼 **바꿀 수 있는 게 "발신지 포트"밖에 없어서** 포트가 병목이 된다.

    - 예시로, 사용 가능한 발신지 포트가 60,000개이고 TIME_WAIT(=2MSL)가 120초면

      같은 클라이언트 IP로 만들 수 있는 새 연결 수는 대략 **초당 500개(60,000/120)** 로 제한된다.

      서버가 아무리 빠르더라도, 클라이언트 쪽이 포트 때문에 더 이상 새 커넥션을 못 만들어서 "성능이 떨어진 것처럼" 보일 수 있다.

- 해결 방향은 "TIME_WAIT을 억지로 줄이는 튜닝"보다 보통 **테스트 환경을 바꾸는 것**이 안전하다.
    - 부하 발생 장비(클라이언트)를 더 늘리기 (클라이언트 IP 다양화)
    - 클라이언트/서버에 가상 IP를 추가해서 **4-튜플 조합 수**를 늘리기
    - (핵심 아이디어) 한두 대 클라이언트로 커넥션을 미친 듯이 만들면 포트가 먼저 고갈된다.
- 추가로, 포트 고갈까지는 안 가도 **동시에 너무 많은 커넥션/제어 블록**이 쌓이면 OS에 따라 극심하게 느려질 수 있으니(커널 리소스 압박), 그 자체도 주의 포인트다.

## 4.3 HTTP 커넥션 관리

앞의 두 절에서는 **TCP 커넥션이 어떤 식으로 동작하고**, 그 때문에 **HTTP 성능에 어떤 영향**이 생기는지 큰 그림으로 다뤘다.

이 절에서는 "HTTP에서 커넥션을 어떻게 만들고, 어떻게 최적화하는지"에 대한 기술들이다.

### 4.3.1 흔히 잘못 이해하는 Connection 헤더

- HTTP는 프록시/캐시를 거치며 hop 단위로 전달된다.
- `Connection` 헤더는 "현재 hop(현재 커넥션)에만 적용되는 옵션"을 지정한다.
- `Connection` 토큰에는 (a) hop-by-hop 헤더 이름, (b) 비표준 옵션 토큰, (c) `close`가 올 수 있다.
- 프록시는 다음 hop으로 넘기기 전에 `Connection` 헤더와 거기에 적힌 헤더들을 **반드시 삭제**해야 한다.
- `Transfer-Encoding`, `Upgrade` 같은 일부 hop-by-hop 헤더는 원래부터 hop 단위라 특히 주의한다.

<img width="495" height="202" alt="image" src="https://github.com/user-attachments/assets/c02b57b3-cc87-48b3-8dda-125a60b49244" />

### 4.3.2 순차적인 트랜잭션 처리에 의한 지연

- 웹페이지는 보통 HTML 하나만 받는 게 아니라, **이미지/JS/CSS 같은 리소스**를 같이 받아야 한다.

  예를 들어 이미지 3개가 붙은 페이지면 **HTTP 트랜잭션이 최소 4개**(HTML 1 + 이미지 3) 필요하다.

  <img width="481" height="195" alt="image" src="https://github.com/user-attachments/assets/4152b934-f8ee-4b9a-8870-70953637e740" />

- 만약 이 4개 요청이 **매번 새 TCP 커넥션**을 만든다면, 요청마다
    1. **TCP 핸드셰이크 지연(커넥션 맺는 비용)**
    2. **TCP Slow Start 지연(초반 전송량 제한)**

       이 두 가지가 반복해서 붙는다. 그래서 전체 로딩이 확 느려진다.

- 리소스를 **순차적으로 하나씩** 받으면 **물리적 지연**뿐 아니라 **심리적 지연**도 커진다.

  한 이미지를 받는 동안 화면이 멈춰 보이면 사용자는 더 느리다고 느낀다.

- 순차 로딩의 또 다른 단점: 어떤 브라우저는 객체 배치를 위해 **리소스 크기**를 알아야 해서, 다 받기 전까지 **빈 화면(화이트 스크린)** 을 보여주기도 한다.
- 그래서 HTTP 성능을 끌어올리는 핵심은 **커넥션을 어떻게 쓰느냐(관리/재사용/동시성)** 이고, 책은 다음 4가지 기술을 소개한다:
    1. **병렬(Parallel) 커넥션**: 여러 TCP 커넥션으로 동시에 요청
    2. **지속(Persistent) 커넥션**: 커넥션을 재활용해서 핸드셰이크/slow start 비용 줄임
    3. **파이프라인(Pipelined) 커넥션**: 하나의 TCP 커넥션에 요청을 연속으로 보내 병렬처럼 활용
    4. **다중(Multiplexed) 커넥션**: 하나의 커넥션에서 요청/응답을 섞어 처리(중재)하는 방식

## 4.4. 병렬 커넥션

브라우저는 HTML 페이지, 여러객체를 하나씩 내려받는 식으로 웹페이지를 보여줄 수 있지만 너무 느리다.

HTTP는 클라이언트가 여러 개의 커넥션을 맺음으로써 여러 개 의 HTTP 트랜책션을 병렬로 처리할 수 있게 한다.

<img width="492" height="261" alt="image" src="https://github.com/user-attachments/assets/78fb15b6-4133-499c-9a51-26de7810145a" />

### 4.4.1 병렬 커넥션은 페이지를 더 빠르게 내려받는다

- 단일 커넥션은 대역폭 한계와 객체별 대기 시간이 순차로 누적된다.
- 커넥션에는 실제 전송 외에도 놀고 있는 시간이 생긴다.
- 병렬 커넥션은 여러 커넥션의 지연 시간을 겹쳐 총 지연을 줄인다.
- 한 커넥션이 대역폭을 다 못 쓰면, 남는 대역폭을 다른 커넥션이 활용한다.
- 그래서 HTML 이후 이미지/객체를 동시에 받아 페이지가 더 빨리 로드된다.

### 4.4.2  병렬 커넥션이 항상 더 빠르지는 않다

- 대역폭이 좁으면 병렬로 받아도 같은 파이프를 나눠 써서 이득이 거의 없다.
- 병렬 커넥션은 메모리/커널 자원을 더 써서 자체 오버헤드가 생긴다.
- 객체가 많다고 수백 커넥션을 열면 서버는 동시 커넥션 부담으로 성능이 떨어진다.
- 100명×100커넥션이면 서버는 10,000 커넥션을 처리해야 한다.
- 그래서 브라우저는 병렬 커넥션 수를 제한하고, 서버도 과도한 커넥션을 끊을 수 있다.

<img width="496" height="229" alt="image" src="https://github.com/user-attachments/assets/ae7820ad-6645-4a83-9332-fd47c46e6d46" />

### 4.4.3 병렬 커넥션은 더 빠르게 '느껴질 수' 있다.

- 병렬 커넥션이 항상 총 다운로드 시간을 줄이진 않는다.
- 그래도 여러 객체가 동시에 로딩되는 "진행감"을 보여준다.
- 사용자는 진행 상황이 보이면 더 빠르다고 느낀다.
- 사람은 총 시간보다 화면 피드백/동시 변화에 영향을 많이 받는다.
- 그래서 병렬은 "실제 속도"보다 "체감 속도"를 개선할 수 있다.

## 4.5 지속 커넥션

- 웹 클라이언트는 보통 **같은 사이트에 여러 번 요청** 한다.
    - HTML을 받고 나면 같은 서버에서 이미지/CSS/JS를 또 받아야 하고, 링크도 같은 도메인으로 이어지는 경우가 많다. 이런 특성을 **사이트 지역성(site locality)**이라고 부른다.
- HTTP/1.1은 요청이 끝나도 TCP 커넥션을 유지해서 재사용할 수 있다.
- 이렇게 유지되는 연결이 지속 커넥션이고, 매번 끊는 건 비지속 커넥션이다.
- 지속 커넥션은 핸드셰이크 같은 연결 준비 시간을 줄인다.
- 이미 열린 커넥션은 Slow Start 지연을 덜 타서 전송이 더 빠를 수 있다.

### 4.5.1 지속 커넥션 VS 병렬 커넥션

- 병렬 커넥션은 빠르게 보이지만, 매 요청마다 새 연결 + Slow Start로 비용이 크다.
- 병렬 커넥션 수는 브라우저/서버 정책 때문에 제한된다.
- 지속 커넥션은 연결 비용을 줄이고 튜닝된 커넥션을 재사용하며 커넥션 수를 줄인다.
- 대신 관리가 나쁘면 유휴 커넥션이 쌓여 리소스 낭비가 생긴다.
- 실전에서는 "소수의 병렬 커넥션 + 지속 유지" 조합이 가장 효과적이다.

### 4.5.2 HTTP/1.0+의 Keep-Alive 커넥션

- HTTP/1.0 브라우저/서버가 확장으로 keep-alive(지속 커넥션)를 도입했다(1996년경).
- 초기 keep-alive는 실험적이라 호환성/설계 문제가 있었지만 HTTP/1.1에서 개선되었다.
- keep-alive는 아래와 같이 여러 트랜잭션을 한 커넥션으로 처리해 연결 생성/종료 비용을 줄여 시간을 단축한다.

<img width="481" height="369" alt="image" src="https://github.com/user-attachments/assets/873e1424-0035-43fe-a4ce-7f0ba9073069" />

### 4.5.3 Keep-Alive 동작

- Keep-Alive는 HTTP/1.1 최종 명세에서는 빠졌지만 현장에선 여전히 많이 쓰인다.
- HTTP/1.0 클라이언트는 연결 유지를 원하면 요청에 `Connection: Keep-Alive`를 넣는다.
- 서버도 유지에 동의하면 응답에 같은 헤더를 넣어준다(핸드셰이크).
- 응답에 `Connection: Keep-Alive`가 없으면 클라이언트는 "지원 안 함/응답 후 종료"로 추정한다.
- 그래서 keep-alive 처리 로직은 호환성 때문에 여전히 필요하다.

<img width="466" height="255" alt="image" src="https://github.com/user-attachments/assets/a19ad497-30a2-4352-9f3c-4b6f6b97cc60" />

### 4.5.4 Keep-Alive 옵션

- `Connection: Keep-Alive`는 "커넥션 유지하고 싶다"는 **희망/요청**이지, 강제 규칙이 아니다. 서버/클라이언트는 언제든 끊을 수 있다.
- 유지 정책은 `Keep-Alive` 헤더의 옵션으로 힌트를 줄 수 있다.
    - `timeout`: 대략 **몇 초 동안** 유지할지
    - `max`: 대략 **몇 개 트랜잭션까지** 처리할지
- `timeout/max`는 **보장값이 아니라 참고값**이다. 상황에 따라 서버가 더 빨리 끊을 수 있다.
- `Keep-Alive: ...`는 보통 **`Connection: Keep-Alive`가 있을 때만** 의미 있게 같이 쓴다.

```jsx
Connection: Keep-Alive
Keep-Alive: max=5, timeout=120
```

- 최대 5번 정도 더 쓰거나, 최대 120초 정도 유지

### 4.5.5 Keep-Alive 커넥션 제한과 규칙

- **HTTP/1.0은 기본이 keep-alive 아님** → 쓰려면 요청에 `Connection: Keep-Alive`를 넣어야 한다.
- **계속 유지하려면 매 요청마다** `Connection: Keep-Alive`를 넣는 게 원칙. 안 넣으면 서버가 **응답 후 끊을 수 있음**.
- **응답에 `Connection: Keep-Alive`가 없으면** 클라이언트는 "서버가 응답 후 끊는다"고 판단.
- keep-alive는 한 연결에서 메시지가 이어지니까 **본문 끝(메시지 경계)** 을 정확히 알아야 함 →

  `Content-Length`가 정확하거나, (또는) chunked 같은 방식이어야 한다.

- **프록시/게이트웨이는** 포워딩/캐시 전에`Connection` 헤더 + 거기에 명시된 헤더들을 **반드시 제거**해야 한다.
- 정석대로라면 `Connection`을 이해 못 하는 프록시(멍청한 프록시)가 경로에 있으면 **keep-alive를 쓰면 안 됨**(하지만 현실에선 식별/회피가 어려움).
- **HTTP/1.0 장비에서 온 Connection 헤더는 무시**하라는 규칙도 있음(구형 프록시가 실수로 전달할 수 있어서). 다만 실무에선 호환성 때문에 안 지키는 경우도 있음.
- 응답을 다 받기 전에 끊기면 클라이언트는 **문제 없을 때 재시도**할 준비가 필요(중복 요청 리스크는 별도 관리).

### 4.5.6 Keep-Alive와 멍청한(dumb) 프락시

- `Connection: Keep-Alive`는 **현재 hop(클라이언트↔프록시)** 에만 의미가 있는 **hop-by-hop 헤더**다.
- 그런데 멍청한 프록시는 Connection헤더에 대한 처리 방법을 몰라 **삭제하지 않고 서버로 그대로 전달**한다.

<img width="494" height="320" alt="image" src="https://github.com/user-attachments/assets/9b602474-c4e3-4308-8d2f-9d1a59c27caf" />

**잘못된 통신 예시**

- 클라이언트 → 프록시: `Connection: Keep-Alive` (연결 유지 희망)
- 멍청한 프록시 → 서버: Connect 헤더를 그대로 전달
- 서버는 "프록시가 나랑 keep-alive 원하네"라고 **오해**하고 연결을 안 끊음
- 프록시는 keep-alive를 몰라서 "서버가 끊어주겠지" 하며 **끊기만 기다림**
- 클라이언트는 "유지되는 줄 알고" 같은 연결로 다음 요청을 보냄
- 프록시는 같은 연결에서 두 번째 요청을 처리 못 해서 **무시/먹통**
- 브라우저는 **로딩만 돌다가 타임아웃**

이러한 통신을 피하려면 프록시는 **hop-by-hop 헤더를 다음 hop으로 넘기면 안 됨**.

- 그리고 `Connection`에 안 적혀 있어도, 애초에 **hop-by-hop 성격인 헤더들**이 있다.

  이런 것들도 프록시는 **전달하거나 캐시하면 안 됨**:

    - `Proxy-Authenticate`
    - `Proxy-Connection`
    - `Transfer-Encoding`
    - `Upgrade`

### 4.5.7  Proxy-Connection 살펴보기

- 멍청한 프록시는 `Connection: Keep-Alive` 같은 **hop-by-hop 헤더를 삭제하지 않고 그대로 전달**해서, 서버가 "프록시가 나랑 keep-alive 하자고 하네"라고 **오해**하는 문제가 생긴다.
- **넷스케이프의 차선책**: 브라우저가 프록시로 보낼 때 `Connection` 대신 **비표준 헤더 `Proxy-Connection`** 을 사용한다.

  멍청한 프록시가 이걸 서버로 넘겨도 서버는 보통 **무시**하므로 오해가 줄어든다.

- **영리한 프록시라면** `Proxy-Connection`을 이해하고, 서버로 전달할 때 **`Connection: Keep-Alive`로 변환**해서 keep-alive를 성립시킬 수 있다.
- **한계**:
    1. **프록시가 1개일 때만**  잘 동작한다. 프록시가 여러 단계면 다시 헤더가 꼬일 수 있다.
    2. 방화벽/캐시/가속기 같은 **'보이지 않는(transparent) 프록시'** 는 브라우저가 존재를 몰라서 `Proxy-Connection`을 보낼 수 없다.
- **결론**: `Proxy-Connection`은 멍청한 프록시 문제를 줄이려는 **임시방편(비표준 꼼수)** 이고, 모든 환경에서 안전한 해결책은 아니다.

> 💡 한 줄 요약
> - 멍청한 프록시 때문에 "원래는 한 hop에서만 의미 있어야 할 keep-alive 의사표현(Connection 헤더)"이 다음 hop으로 새어 나가서, 각자(클라/프록시/서버)가 서로 다른 기대를 하게 되고, 그 결과 '누군가는 끊어야 한다고 생각하고, 누군가는 안 끊는다' 같은 연결 불일치가 생긴다.

- Keep-alive 커넥션은 hop-by-hop간에만 유지되어야 한다.

<img width="561" height="443" alt="image" src="https://github.com/user-attachments/assets/36910ffa-4eeb-44fb-b154-76e4c4172ad6" />

- `Proxy-Connection` 을 보냄으로써 멍청한 프록시가 껴있으면 Keep-alive 연결 요청을 무시한다.
- 영리한 프록시라면 헤더를 `Connection: Keep-Alive` 로 변경하여 요청한다.
    - 이러면 클라이언트 ↔ 영리한 프록시
    - 영리한 프록시 ↔ 서버  (Optional)
    - 간에 keep-alive연결이 이루어진다.

<img width="560" height="408" alt="image" src="https://github.com/user-attachments/assets/0fc14932-1c7e-4358-88c9-a999ca9c927a" />

- 홉이 2개 이상일때 멍청한 프록시가 껴있다면 `Proxy-Connection`을 사용해도 문제가 발생할 수 있다.
    - EX)위의 그림에서 상단 케이스 예시
        - 클라이언트는 연결 유지 되었다고 생각
        - 영리한 프록시는 Proxy-Connection을 알아들으니 연결 유지 되었다고 생각
        - (e) 멍청한 프록시는 연결 유지 모름
            - 연결끊어주기를 기다림
        - 클라이언트가 기존 커넥션에서 요청
        - 멍청한 프록시는 영리한 프록시가 연결끊어주기를 기다리고 있어 요청 무시

### 4.5.8 HTTP/1 .1 의 지속 커넥션

- HTTP/1.1에서는 keep-alive 커넥션을 지원하지 않는 대신, 설계가 더 개선된 지속 커넥션을 지원한다.
    - 목적은 keep-alive 커넥션과 같다.
- HTTP/1.0의 keep-alive 커넥션과는 달리 HTTP/1.1의 지속 커넥션은 기본으로 활성화되어 있다.
- HTTP/1.1 애플리케이션은 트랜잭션이 끝난 다음 커넥션을 끊으려면 `Connection: close` 헤더를 명시해야 한다.
- `Connection: close` 가 응답에 없으면 지속 커넥션을 유지하는 것으로 간주하지만 영원히 커넥션을 유지하는 것을 뜻하진 않으므로 서버나 클라이언트는 언제든 커넥션을 끊을 수 있다.

### 4.5.9 지속 커넥션의 제한과 규칙

- 요청에 `Connection: close`를 붙였으면 **그 요청이 마지막**. 같은 연결로 다음 요청 보내면 안 된다.
- **요청이 마지막 요청이라면 `Connection: close` 붙여서 보내야 한다.**
- 지속 커넥션은 **메시지 경계**가 확실해야 한다.

  → 본문은 **정확한 `Content-Length`** 이거나 **chunked** 여야 함.

  (`Content-Length` 틀리면 다음 메시지랑 섞여서 터짐)

- 프록시가 끼면 지속 커넥션은 **hop 단위**로 관리해야 함.

  → 클라↔프록시, 프록시↔서버 **각각 별도 커넥션**

- 원칙적으로 프록시는 클라이언트가 커넥션 기능을 제대로 지원하는지 모르면 **지속 커넥션을 함부로 맺지 않아야 한다**
    - (구형 프록시/헤더 꼬임 때문). 현실은 벤더들이 종종 무시함.
- HTTP/1.1에서는 `Connection` 헤더랑 상관없이 **언제든 커넥션이 끊길 수 있다.**
- 클라이언트는 **중간에 끊겼을 때 복구/재시도**가 가능해야 함.

  특히 **다시 보내도 안전한 요청**이면 재시도 준비.

- 서버 보호하려고 클라는 보통 **지속 커넥션 2개 정도만 유지**하라고 권장.

## 4.6 파이프라인 커넥션

- HTTP/1.1은 **지속 커넥션**을 기반으로 요청을 **파이프라이닝(pipelining)** 할 수 있다.
    - 목적은 응답을 기다리지 않고 여러 요청을 연속으로 보내서, **왕복 지연(RTT)** 으로 인한 대기 시간을 줄이는 것이다.
- 파이프라이닝을 사용하면 첫 번째 요청이 서버로 전송되는 동안, 두 번째·세 번째 요청도 같은 커넥션에 **연속으로 큐에 쌓아 전송**할 수 있다.
    - 지연이 큰 네트워크 환경에서 성능 개선 효과가 크다.
- 파이프라이닝은 **지속 커넥션이 확실할 때만** 사용해야 한다.
    - 커넥션이 지속 커넥션인지 확인되기 전에는 파이프라이닝을 시작하면 안 된다.
- 파이프라이닝에서 **응답은 요청 순서대로** 와야 한다.
    - HTTP 메시지는 요청/응답에 순번이 없어서, 응답이 순서 없이 오면 클라이언트가 재정렬할 방법이 없다.
- 커넥션은 언제든 끊길 수 있으므로, 클라이언트는 파이프라인에 **미완료 요청이 남아 있는 상태에서 커넥션이 끊어져도 재전송**할 준비가 되어 있어야 한다.
    - 예를 들어 일부 요청만 처리된 뒤 커넥션이 끊기면, 남은 요청은 실패하고 클라이언트가 다시 연결해 재요청해야 한다.
- `POST`처럼 **비멱등(non-idempotent)** 요청은 파이프라이닝으로 보내면 안 된다.
    - 오류/끊김이 발생했을 때 어떤 요청이 서버에서 처리되었는지 알기 어려워, 재전송 시 **중복 처리** 문제가 생길 수 있다.

<img width="504" height="568" alt="image" src="https://github.com/user-attachments/assets/4ade1c2e-c775-40e0-8d3c-379eabcaca90" />

## 4.7 커넥션 끊기에 대한 미스터리

커넥션 관리(특히 언제 어떻게 커넥션을 끊는가)에는 명확한 기준이 없다.

### 4.7.1 `마음대로` 커넥션 끊기

- HTTP에서는 클라이언트/서버/프록시 누구든 **언제든지 TCP 커넥션을 끊을 수 있다.**
    - 보통은 메시지를 다 보낸 뒤 끊지만, 에러 상황에서는 **헤더 중간 같은 애매한 지점에서 끊길 수도 있다.**
- 이 문제는 **파이프라인 지속 커넥션**에서 특히 중요하다.
    - 지속 커넥션은 언제든 서버가 임의로 끊을 수 있고, 예를 들어 커넥션이 일정 시간 **유휴(idle)** 상태면 서버가 끊어버릴 수 있다.
- 다만 서버가 유휴 커넥션을 끊는 순간에도, 클라이언트가 **정말로 더 이상 데이터를 안 보낼지 확신할 수는 없다.**
    - 그래서 타이밍이 겹치면, 클라이언트는 **요청을 보내는 도중에 커넥션이 끊겨 실패**할 수 있다.

### 4.7.2 Content-Length와 Truncation

- 각 HTTP 응답은 본문의 정확한 크기를 나타내는 **`Content-Length`** 를 가져야 한다.
    - 하지만 오래된 서버 중에는 "커넥션을 끊으면 전송이 끝"이라는 방식에 기대서 `Content-Length`를 **빼먹거나 틀리게 보내는 경우**가 있다.
- 클라이언트/프록시는 응답을 받다가 커넥션이 끊겼을 때, 실제 받은 바이트 수와 `Content-Length`가 **일치하지 않거나 `Content-Length`가 없으면**
    - 수신한 본문이 **잘린 데이터일 수 있다**고 보고 정확한 길이를 서버에 재요청 해야 한다.
- 수신자가 **캐시 프록시**라면, 이런 응답은 **캐시하면 안 된다.**
    - 프록시는 `Content-Length`를 멋대로 고쳐서 "정상 응답처럼" 만들려고 하지 말고, **받은 그대로 전달**해야 한다.

### 4.7.3 커넥션 끊기의 허용, 재시도, 멱등성

- 커넥션은 **에러가 없어도 언제든 끊길 수 있다.**
    - 그래서 HTTP 애플리케이션은 **예상치 못한 커넥션 종료에 대응할 준비**가 되어 있어야 한다.
- 트랜잭션 수행 중 커넥션이 끊기면, 클라이언트는 **재시도해도 문제가 없는 요청이라면** 커넥션을 다시 맺고 **한 번 더 전송**해야 한다.
- 이 문제는 **파이프라인 커넥션**에서 더 까다롭다.
    - 클라이언트는 여러 요청을 큐에 쌓아두지만, 서버는 일부 요청을 처리하지 않은 채로 **커넥션을 끊어버릴 수도 있다.**
- 요청 데이터를 보냈는데 응답이 오기 전에 커넥션이 끊기면, 클라이언트는 **서버가 어디까지 처리했는지 알 방법이 없다.**
    - `GET`처럼 반복해도 결과가 변하지 않는 요청은 큰 문제가 없지만,
    - `POST(주문)`처럼 반복하면 결과가 달라지는 요청은 **중복 처리**가 될 수 있다.
- 여러 번 실행돼도 결과가 같으면 그 트랜잭션은 **멱등(idempotent)** 하다고 한다.
    - 일반적으로 `GET`, `HEAD`, `PUT`, `DELETE`, `TRACE`, `OPTIONS` 는 멱등하다고 본다.
- 클라이언트는 `POST`처럼 **비멱등(non-idempotent)** 요청은 파이프라인으로 보내면 안 된다.
    - 커넥션이 끊겼을 때 재전송하면 **알 수 없는 결과(중복 주문 등)** 가 생길 수 있기 때문이다.
    - 비멱등 요청을 다시 보내야 한다면, **이전 요청의 응답을 받은 뒤**에 해야 한다.
- 비멱등 요청은 자동 재시도를 하면 안 된다.
    - 그래서 브라우저도 `POST`를 다시 보내야 하는 상황이면 보통 **사용자에게 재전송 여부를 묻는 팝업**을 띄운다.

### 4.7.4 우아한 커넥션 끊기

TCP 커넥션은 양방향이다.

<img width="461" height="142" alt="image" src="https://github.com/user-attachments/assets/7fb6c7ae-b0d8-4dcc-aa0a-284a9f4b4a5b" />

**전체 끊기와 절반 끊기**

- 애플리케이션은 TCP에서 **입력(읽기) 채널**과 **출력(쓰기) 채널**을 **둘 다 끊을 수도 있고, 한쪽만 끊을 수도 있다.**
- `close()`를 호출하면 **입력/출력 채널을 모두 끊는다.**
    - 이를 **전체 끊기** 라고 한다.
- `shutdown()`을 호출하면 **입력 또는 출력 채널 중 하나만 선택적으로 끊을 수 있다.**
    - 이를 **절반 끊기**라고 한다.

<img width="481" height="316" alt="image" src="https://github.com/user-attachments/assets/4ae0eb93-a680-4449-8767-779c931c988c" />

**TCP 끊기와 리셋 에러**

- 단순한 HTTP 애플리케이션은 보통 `close()`로 **전체 끊기**만 사용한다.
    - 하지만 서로 다른 클라이언트/서버/프록시랑 통신하고, 특히 **파이프라인 지속 커넥션**까지 쓰는 환경에서는

      예상치 못한 **쓰기 에러를** 피하려고 **절반 끊기**를 사용해야 한다.

- 일반적으로는 **출력 채널(쓰기 방향)을 끊는 게 안전**하다.
    - 내가 "이제 더 이상 보낼 건 없음"을 알리면, 반대편은 남아 있던 데이터를 다 읽고 나서 **송신 종료(EOF 같은 신호)** 를 인지할 수 있다.
- 반대로 **입력 채널(읽기 방향)을 먼저 끊는 건 위험**하다.
    - 아직 상대가 나에게 데이터를 보내고 있을 수도 있는데,

      내가 읽기를 닫아버리면 상대가 보내는 순간 OS가 **`connection reset by peer`(RST)** 를 날릴 수 있다.

- `connection reset by peer`가 무서운 이유는, 많은 OS가 이걸 **심각한 오류로 보고**

  **아직 애플리케이션이 읽지 않은 수신 버퍼 데이터까지 통째로 버려버릴 수 있다**는 점이다.

    - 즉, 데이터가 내 장비에 도착했어도 "앱이 아직 안 읽었으면" 사라질 수 있다.
- 파이프라인에서는 이게 더 치명적이다. 예를 들어:
    - 요청 10개를 파이프라인으로 보냈고, 그에 대한 응답이 **이미 OS 수신 버퍼에 쌓여 있는데** 앱은 아직 읽지 않았다고 하자.
    - 그 상태에서 11번째 요청을 보냈는데, 서버가 "이 커넥션 오래 썼네" 하고 끊어버렸다면

      11번째 요청은 **끊긴 커넥션에 쓰는 꼴**이 되고,

    - 서버는 요청을 처리하지 않고 **RST(`connection reset by peer`)** 로 응답할 수 있다.
    - 이 RST 때문에, 이미 버퍼에 있던 1~10번 응답 데이터까지 **같이 날아갈 수 있다.**
- 결과적으로 클라이언트는 읽으려고 할 때 `connection reset by peer` 에러를 받고,

  "응답이 도착했는데도(버퍼에 있었는데도)" 아직 읽지 않았던 데이터는 **유실**될 수 있다.

<img width="468" height="176" alt="image" src="https://github.com/user-attachments/assets/c0421eea-b3cd-4c57-ad4a-93ffae8cb9bb" />

**우아하게 커넥션 끊기**

- HTTP 명세는 "예기치 않게 끊어야 하면 **우아하게 끊어라**"라고만 하고, 방법은 자세히 안 알려준다.
- 일반적으로 **우아하게 끊기란 출력부터 닫고**, 상대도 쓰기를 닫을 때까지 **기다리는 방식**이다.
    - 양쪽이 "더 이상 보낼 데이터 없음"을 확인하면 **RST(리셋) 위험 없이** 종료된다.
- 문제는 상대가 **절반 끊기(shutdown)** 를 지원/사용한다는 보장이 없다는 것.
    - 그래서 내 출력 채널을 절반 끊기한 뒤에도, 입력 채널에서 **끊김 여부를 주기적으로 확인**해야 한다.
- 일정 시간(timeout) 내에 상대가 안 끊으면, 리소스 보호를 위해 **강제로 커넥션을 끊을 수 있다.**
